{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by installing nnabla and accessing nnabla-examples repository. If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime â†’ change runtime type), and make sure to click Connect on the top right-hand side of the screen before you start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28074,
     "status": "ok",
     "timestamp": 1651061350099,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "O4EiMClffwir",
    "outputId": "56eee9ee-7028-494a-d5b8-eda1b4a8990d"
   },
   "outputs": [],
   "source": [
    "# May show warnings for newly imported packages if run in Colab default python environment.\n",
    "# Please click the `RESTART RUNTIME` to run the following script correctly.\n",
    "# The error message of conflicts is acceptable.\n",
    "!pip install nnabla-ext-cuda116\n",
    "!git clone https://github.com/sony/nnabla-examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd nnabla-examples/object-detection/centernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1651061372051,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "7399f25f",
    "outputId": "6146a966-9362-4a26-dcf7-e586f1525e6e"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import nnabla as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from nnabla.utils.image_utils import imread\n",
    "from nnabla.ext_utils import get_extension_context\n",
    "from PIL import Image\n",
    "\n",
    "ctx = get_extension_context('cudnn')\n",
    "nn.set_default_context(ctx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3ef2cfb0"
   },
   "source": [
    "Then you need to choose backbone network architecture and dataset the pretrained model has been trained on. Just click the dropdown list and select one for each. After you choose, execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1651061376441,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "54fc96fc"
   },
   "outputs": [],
   "source": [
    "#@title Choose backbone architecture and dataset which the model is trained on.\n",
    "architecture = 'dlav0' #@param ['resnet', 'dlav0']\n",
    "\n",
    "#@title Choose dataset\n",
    "dataset = 'coco' #@param ['coco', 'pascal']\n",
    "\n",
    "if architecture == \"resnet\":\n",
    "    num_layer = 18\n",
    "else:\n",
    "    num_layer = 34\n",
    "param_url = f\"https://nnabla.org/pretrained-models/nnabla-examples/object-detection/ceneternet/ctdet/{architecture}_{num_layer}_{dataset}_fp.h5\"\n",
    "param_path = param_url.split(\"/\")[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now download the pre-trained weight parameters for the selected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1651061380088,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "7a7614c3",
    "outputId": "65e00819-005e-4534-c807-ddd9f5453eb4"
   },
   "outputs": [],
   "source": [
    "!wget $param_url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CenterNet detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1651061382179,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "gHMVeubLorff"
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1651061384929,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "7dd446c5",
    "outputId": "d9f872d6-c6f9-43ec-d7c8-c2570834fd6e"
   },
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "from opts import opts\n",
    "from detectors.detector_factory import detector_factory\n",
    "from datasets.dataset.pascal_config import PascalVOCDefaultParams\n",
    "from datasets.dataset.coco_config import COCODefaultParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1651061387403,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "KpN0s-BPpXkp",
    "outputId": "ade66517-abc1-4da6-bd25-11c2add20e8d"
   },
   "outputs": [],
   "source": [
    "o = opts()\n",
    "opt, _ = o.parser.parse_known_args([\"--task\", \"ctdet\", \"--arch\", architecture, \"--dataset\", dataset, \"--checkpoint\", param_path, \"--save_dir\", \"./\", \"--debug\", \"1\",])\n",
    "opt.head_conv = 256 if 'dlav0' in opt.arch else 64\n",
    "opt.down_ratio = 4\n",
    "opt.pad = 31\n",
    "opt.num_stacks = 1\n",
    "opt.test_scales = [1.0]\n",
    "opt.fix_res = True\n",
    "default_dataset_info = {\n",
    "  'coco': COCODefaultParams,\n",
    "  'pascal': PascalVOCDefaultParams,\n",
    "}\n",
    "dataset_para = default_dataset_info[dataset]\n",
    "opt = o.update_dataset_info_and_set_heads(opt, dataset_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1651061390556,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "BxHU9pUE5MiQ",
    "outputId": "7fb0f690-dd86-4d92-cd9b-53ad810a36cf"
   },
   "outputs": [],
   "source": [
    "nn.set_auto_forward(True) \n",
    "Detector = detector_factory[opt.task]\n",
    "detector = Detector(opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Image\n",
    "Run the following cell to upload your own image. Note that too small images might cause poor result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 9660,
     "status": "ok",
     "timestamp": 1651061401948,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "b2d5e164",
    "outputId": "cb39e53f-6780-478c-8e42-98d19457d0b6"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "img = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1651061404019,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "sL6VTGgbt0o5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ext = os.path.splitext(list(img.keys())[-1])[-1]\n",
    "os.rename(list(img.keys())[-1], \"input_image{}\".format(ext)) \n",
    "input_img = \"input_image\" + ext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "Now let's run CenterNet on your image and see how it performs object detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3007,
     "status": "ok",
     "timestamp": 1651061408736,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "e18b2f63"
   },
   "outputs": [],
   "source": [
    "ret = detector.run(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "executionInfo": {
     "elapsed": 1562,
     "status": "ok",
     "timestamp": 1651061411596,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "0ab1bcbd",
    "outputId": "6b006470-42c9-49d5-f451-279c5bf4e612"
   },
   "outputs": [],
   "source": [
    "Image.open(\"./ctdet.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization using Eigen-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1651061414165,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "a2600d90"
   },
   "outputs": [],
   "source": [
    "def eigencam(middle_layer, eigenvector_index=0):\n",
    "    \"\"\"\n",
    "    Calculate EigenCAM.\n",
    "    Parameters\n",
    "    ----------\n",
    "    middle_layer: nn.Variable\n",
    "        The layer of interest to apply EigenCAM\n",
    "    Returns\n",
    "    ----------\n",
    "    heatmap: ndarray\n",
    "        2D array of same size as width and height of middle_layer\n",
    "    \"\"\"\n",
    "    conv_layer_output = middle_layer.d\n",
    "    heatmap = get_2d_projection(conv_layer_output, eigenvector_index)\n",
    "    max_v, min_v = np.max(heatmap), np.min(heatmap)\n",
    "    if max_v != min_v:\n",
    "        heatmap = (heatmap - min_v) / (max_v - min_v)\n",
    "    return heatmap[0]\n",
    "\n",
    "def get_2d_projection(activation_batch, eigenvector_index=0):\n",
    "    # https://github.com/jacobgil/pytorch-grad-cam/blob/master/pytorch_grad_cam/utils/svd_on_activations.py\n",
    "    # TBD: use pytorch batch svd implementation\n",
    "    activation_batch[np.isnan(activation_batch)] = 0\n",
    "    activation_batch[np.isinf(activation_batch)] = 0\n",
    "    \n",
    "    projections = []\n",
    "    for activations in activation_batch:\n",
    "        reshaped_activations = (activations).reshape(\n",
    "            activations.shape[0], -1).transpose()\n",
    "        # Centering before the SVD seems to be important here,\n",
    "        # Otherwise the image returned is negative\n",
    "        reshaped_activations = reshaped_activations - \\\n",
    "            reshaped_activations.mean(axis=0)\n",
    "        U, S, VT = np.linalg.svd(reshaped_activations, full_matrices=True)\n",
    "        projection = reshaped_activations @ VT[eigenvector_index, :]\n",
    "        projection = projection.reshape(activations.shape[1:])\n",
    "        projections.append(projection)\n",
    "    return np.float32(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1651061415396,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "7e2e3a0f"
   },
   "outputs": [],
   "source": [
    "def overlay_images(base_img, overlay_img, overlay_coef=1.0):\n",
    "    # resize\n",
    "    _overlay_img = cv2.resize(\n",
    "        overlay_img, (base_img.shape[1], base_img.shape[0]))\n",
    "    \n",
    "    # normalize\n",
    "    _overlay_img = 255 * _overlay_img / _overlay_img.max()\n",
    "    _overlay_img = _overlay_img.astype('uint8')\n",
    "    \n",
    "    # color adjust\n",
    "    _overlay_img = cv2.applyColorMap(_overlay_img, cv2.COLORMAP_JET)\n",
    "    base_img = cv2.cvtColor(base_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # overlay\n",
    "    ret_img = _overlay_img * overlay_coef + base_img\n",
    "    ret_img = 255 * ret_img / ret_img.max()\n",
    "    ret_img = ret_img.astype('uint8')\n",
    "    \n",
    "    ret_img = cv2.cvtColor(ret_img, cv2.COLOR_BGR2RGB)\n",
    "    return ret_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651061415782,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "9cad71ea"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class get_middle_variables:\n",
    "    def __init__(self):\n",
    "        self.middle_vars_dict = OrderedDict()\n",
    "        self.middle_layer_count_dict = OrderedDict()\n",
    "    def __call__(self, f):\n",
    "        if f.name in self.middle_layer_count_dict:\n",
    "            self.middle_layer_count_dict[f.name] += 1\n",
    "        else:\n",
    "            self.middle_layer_count_dict[f.name] = 1\n",
    "        key = f.name + '_{}'.format(self.middle_layer_count_dict[f.name])\n",
    "        self.middle_vars_dict[key] = f.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651061416789,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "da7aee20"
   },
   "outputs": [],
   "source": [
    "img_orig = np.array(Image.open(input_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1651061417522,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "f4e291e2"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(input_img)\n",
    "images, meta = detector.pre_process(image, opt.test_scales[0], None)\n",
    "inputs = nn.Variable.from_numpy_array(images)\n",
    "outputs = detector.model(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get middle layer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651061417829,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "02813f14",
    "outputId": "cd612b2f-fb23-45de-d406-361f91e046fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GET_MIDDLE_VARIABLES_CLASS = get_middle_variables()\n",
    "outputs[0].visit(GET_MIDDLE_VARIABLES_CLASS)\n",
    "middle_vars = GET_MIDDLE_VARIABLES_CLASS.middle_vars_dict\n",
    "middle_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 1584,
     "status": "ok",
     "timestamp": 1651061421165,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "379a1b4f",
    "outputId": "3020d6f8-c7a1-40fa-8910-dcd321466249"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 1)\n",
    "ax.imshow(img_orig)\n",
    "ax.axis(\"off\")\n",
    "plt.title(\"original image\")\n",
    "\n",
    "for i in range(3):\n",
    "    ax = fig.add_subplot(1, 4, i+2)\n",
    "    heatmap = eigencam(middle_vars['ConvolutionCudaCudnn_36'], eigenvector_index=i) #set variables key\n",
    "    overlaid_img = overlay_images(img_orig, heatmap)\n",
    "    plt.title(f\"using\\n  {i+1}st singular vector\")\n",
    "    ax.imshow(overlaid_img)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "934225d8"
   },
   "source": [
    "# Real time Visualization for CenterNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img_str(img_str):\n",
    "    decimg = base64.b64decode(img_str.split(',')[1], validate=True)\n",
    "    decimg = Image.open(BytesIO(decimg))\n",
    "    decimg = np.array(decimg, dtype=np.uint8); \n",
    "    decimg = cv2.cvtColor(decimg, cv2.COLOR_BGR2RGB)\n",
    "    return decimg\n",
    "\n",
    "def encode_img(img):\n",
    "    _, encimg = cv2.imencode(\".jpg\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "    img_str = encimg.tobytes()\n",
    "    img_str = \"data:image/jpeg;base64,\" + base64.b64encode(img_str).decode('utf-8')\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1651061475860,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "XAIEYmAe7gZo"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import base64\n",
    "from google.colab import output\n",
    "from io import BytesIO\n",
    "\n",
    "def run(img_str):\n",
    "    # decode to image\n",
    "    decimg = decode_img_str(img_str)\n",
    "\n",
    "    ##### detection and visualization \n",
    "    images, meta = detector.pre_process(decimg, opt.test_scales[0], None)\n",
    "    inputs = nn.Variable.from_numpy_array(images)\n",
    "    outputs = detector.model(inputs)\n",
    "\n",
    "    GET_MIDDLE_VARIABLES_CLASS = get_middle_variables()\n",
    "    outputs[0].visit(GET_MIDDLE_VARIABLES_CLASS)\n",
    "    middle_vars = GET_MIDDLE_VARIABLES_CLASS.middle_vars_dict\n",
    "\n",
    "    heatmap = eigencam(middle_vars[\"ConvolutionCudaCudnn_35\"], eigenvector_index=1)\n",
    "\n",
    "    out_img = overlay_images(decimg, heatmap)\n",
    "\n",
    "    #encode to string\n",
    "    img_str = encode_img(out_img)\n",
    "\n",
    "    return IPython.display.JSON({'img_str': img_str})\n",
    "\n",
    "output.register_callback('notebook.run', run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1651061582956,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "q4g5_Vtz7oAE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "\n",
    "def use_webcam(quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function useCam(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      document.body.appendChild(div);\n",
    "\n",
    "      // camera btn\n",
    "      var current_deviceId = \"test\";\n",
    "      var new_deviceId = \"test\";\n",
    "      const camera_div = document.createElement('div');\n",
    "      document.body.appendChild(camera_div);\n",
    "      //get deviceIds\n",
    "      navigator.mediaDevices.enumerateDevices()\n",
    "      .then(function(devices) {\n",
    "          devices.forEach(function(device, i) {\n",
    "              //exit button\n",
    "              if (device.deviceId != \"\") {\n",
    "                const canera_btn = document.createElement('button');\n",
    "                canera_btn.textContent = \"camera\" + i;\n",
    "                canera_btn.onclick = function() {\n",
    "                  new_deviceId = device.deviceId\n",
    "                };\n",
    "                camera_div.appendChild(canera_btn);\n",
    "              }\n",
    "          });\n",
    "      })\n",
    "      .catch(function(err) {\n",
    "        console.log(err.name + \": \" + err.message);\n",
    "      });\n",
    "\n",
    "      //video element\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'None';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: { deviceId: current_deviceId } });\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      //canvas for display. frame rate is depending on display size and jpeg quality.\n",
    "      display_size = 500\n",
    "      const src_canvas = document.createElement('canvas');\n",
    "      src_canvas.width  = display_size;\n",
    "      src_canvas.height = display_size * video.videoHeight / video.videoWidth;\n",
    "      const src_canvasCtx = src_canvas.getContext('2d');\n",
    "      src_canvasCtx.translate(src_canvas.width, 0);\n",
    "      src_canvasCtx.scale(-1, 1);\n",
    "      div.appendChild(src_canvas);\n",
    "\n",
    "      const dst_canvas = document.createElement('canvas');\n",
    "      dst_canvas.width  = src_canvas.width;\n",
    "      dst_canvas.height = src_canvas.height;\n",
    "      const dst_canvasCtx = dst_canvas.getContext('2d');\n",
    "      div.appendChild(dst_canvas);\n",
    "\n",
    "      //exit button\n",
    "      const btn_div = document.createElement('div');\n",
    "      document.body.appendChild(btn_div);\n",
    "      const exit_btn = document.createElement('button');\n",
    "      exit_btn.textContent = 'Exit';\n",
    "      var exit_flg = true\n",
    "      exit_btn.onclick = function() {exit_flg = false};\n",
    "      btn_div.appendChild(exit_btn);\n",
    "\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      var send_num = 0\n",
    "      // loop\n",
    "      _canvasUpdate();\n",
    "      async function _canvasUpdate() {\n",
    "\n",
    "            src_canvasCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, src_canvas.width, src_canvas.height);     \n",
    "            if (send_num<1){\n",
    "                send_num += 1\n",
    "                const img = src_canvas.toDataURL('image/jpeg', quality);\n",
    "                const result = google.colab.kernel.invokeFunction('notebook.run', [img], {});\n",
    "                result.then(function(value) {\n",
    "                    parse = JSON.parse(JSON.stringify(value))[\"data\"]\n",
    "                    parse = JSON.parse(JSON.stringify(parse))[\"application/json\"]\n",
    "                    parse = JSON.parse(JSON.stringify(parse))[\"img_str\"]\n",
    "                    var image = new Image()\n",
    "                    image.src = parse;\n",
    "                    image.onload = function(){dst_canvasCtx.drawImage(image, 0, 0)}\n",
    "                    send_num -= 1\n",
    "                })\n",
    "            }\n",
    "            if (exit_flg){\n",
    "                requestAnimationFrame(_canvasUpdate);   \n",
    "            }else{\n",
    "                stream.getVideoTracks()[0].stop();\n",
    "            }\n",
    "            if (new_deviceId != current_deviceId) {\n",
    "              console.log(\"change camera!\");\n",
    "              current_deviceId = new_deviceId;\n",
    "              const stream = await navigator.mediaDevices.getUserMedia({video: { deviceId: current_deviceId } });\n",
    "              video.srcObject = stream;\n",
    "              await video.play();\n",
    "            }\n",
    "      };\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('useCam({})'.format(quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 2420,
     "status": "ok",
     "timestamp": 1651061586896,
     "user": {
      "displayName": "Toya Teramoto",
      "userId": "00439026895970972334"
     },
     "user_tz": -540
    },
    "id": "wnpAQZE87tKm",
    "outputId": "af4e144b-9407-47a4-9f85-66d13907056a"
   },
   "outputs": [],
   "source": [
    "use_webcam()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eigencam_for_CenterNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
