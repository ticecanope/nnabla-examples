{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prejudice Remover Regularizer for Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Data preparation](#2.-Data-preparation)\n",
    "3. [Classifier network](#3.-Classifier-network)\n",
    "\t*  [Model Fairness for Classifier Network](#Model-Fairness-for-Classifier)\n",
    "4. [Prejudice Remover Regularizer](#4.-Prejudice-Remover-Regularizer)\n",
    "\t* [Model Fairness: with PRR](#Model-Fairness:-with-PRR)\n",
    "5. [Summary](#5.-Summary)\n",
    "6. [References](#References)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "Welcome !\n",
    "\n",
    "We hope you have had a chance to go through previous tutorials on fairness in AI by Sony. In one of the tutorials, we applied `Prejudice Remover Regularizer (hereafter referred to as PRR)` technique to train a fair classifier on UCI Adult (Census) Dataset. As a result, model fairness improved without causing much drop in accuracy.\n",
    "\n",
    "In this tutorial, we will explore PRR for visual recognition task on CelebA dataset (real world image dataset).\n",
    "\n",
    "Before we go into a detailed explanation of the PRR training procedure, here is a sneak peek into the steps involved in the process:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Google Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime → change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "# May show warnings for newly imported packages if run in Colab default python environment.\n",
    "# Please click the `RESTART RUNTIME` to run the following script correctly.\n",
    "# The error message of conflicts is acceptable.\n",
    "!git clone https://github.com/sony/nnabla-examples.git\n",
    "!pip install albumentations\n",
    "!pip install nnabla-ext-cuda116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd nnabla-examples/responsible_ai/prejudice_remover_regularizer_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "img = cv2.imread('images/Prejudice_Remover_Regularizer_workflow_diagram.png')\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in the picture, in the first step we will train a classifier model to make predictions & analyze model fairness. Then the subsequent step shows how PRR training can be employed to make the model fair if the fairness metric is not satisfactory.\n",
    "\n",
    "At first, all we need is to import all the necessary python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import nnabla as nn\n",
    "from nnabla.utils.data_iterator import data_iterator_simple\n",
    "import classifier as clf\n",
    "from utils import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train an `Attractive` classifier that is not dependent on gender expression. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preparation\n",
    "\n",
    "Before training a classifier model, let's download and split the CelebA dataset into three categories: training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the celeba dataset and unzip\n",
    "URL = \"https://www.dropbox.com/s/d1kjpkqklf0uw77/celeba.zip?dl=0\"\n",
    "ZIP_FILE= \"./data/celeba.zip\"\n",
    "!mkdir -p ./data/\n",
    "!wget -N $URL -O $ZIP_FILE\n",
    "!unzip $ZIP_FILE -d ./data/\n",
    "!rm $ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_celeba_dataset(img_path, attr_path, out_dir, split=\"test\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    split the celebA dataset\n",
    "    Args:\n",
    "        img_path (str): image path directory \n",
    "        attr_path (str): celebA attribute file path (ex: list_attr_celeba.txt)\n",
    "        out_dir (str): Path where the split data to be saved\n",
    "        split (string): split the dataset depends on the split attribute(train, valid, and test)\n",
    "    \"\"\"\n",
    "    # as per the author's remark, we split the dataset\n",
    "    train_beg = 0  # train starts from\n",
    "    valid_beg = 162770  # valid starts from\n",
    "    test_beg = 182610  # test starts from\n",
    "    \n",
    "    label_file = open(attr_path, 'r')\n",
    "    label_file = label_file.readlines()\n",
    "    \n",
    "    # skipping the first two rows for header\n",
    "    total_samples = len(label_file) - 2\n",
    "    if split == 'train':\n",
    "        number_samples = valid_beg - train_beg\n",
    "        beg = train_beg\n",
    "    \n",
    "    elif split == 'valid':\n",
    "        number_samples = test_beg - valid_beg\n",
    "        beg = valid_beg\n",
    "    \n",
    "    elif split == 'test':\n",
    "        number_samples = total_samples - test_beg\n",
    "        beg = test_beg\n",
    "    else:\n",
    "        print('Error')\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    for i in range(beg + 2, beg + number_samples + 2):\n",
    "        temp = label_file[i].strip().split()\n",
    "        src_dir = os.path.join(img_path,temp[0])\n",
    "        dst_dir = os.path.join(out_dir,temp[0])\n",
    "        shutil.copy(src_dir, dst_dir)\n",
    "    print(\"splitting completed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) is a dataset with 2,022,599 celebrity face images, each with 40 binary attributes labels. \n",
    "\n",
    "Now let us train an `Attractive` classifier that is not dependent on gender expression. `Male` attribute corresponds to gender expression and the target attribute is `Attractive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator_celeba(img_path, attr_path, batch_size,\n",
    "                         target_attribute ='Attractive', protected_attribute = 'Male', \n",
    "                         num_samples=-1, augment=False, shuffle=False, rng=None):\n",
    "    \"\"\"\n",
    "    create celebA data iterator\n",
    "    Args:\n",
    "        img_path (str) : image path directory\n",
    "        attr_path (str) : celebA attribute file path (ex: list_attr_celeba.txt)\n",
    "        batch_size (int) :  number of samples contained in each generated batch\n",
    "        target_attribute (str) : target attribute (ex: Arched EyeBrows, Bushy Eyebrows, smilling,etc..)\n",
    "        protected_attribute (str): protected attribute (ex: Male, Pale_Skin)\n",
    "        num_samples (int) : number of samples taken in data loader\n",
    "                            (if num_samples=-1, it will take all the images in the dataset)\n",
    "        augment (bool) : data augmentation (True for training)\n",
    "        shuffle (bool) : shuffle the data (True /False)\n",
    "        rng : None\n",
    "    Returns:\n",
    "        simple data iterator\n",
    "    \"\"\"\n",
    "\n",
    "    imgs = []\n",
    "    for file in sorted(os.listdir(img_path), key=lambda x: int(x.split(\".\")[0])):\n",
    "        imgs.append(os.path.join(img_path,file))\n",
    "    with open(attr_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    attr_list = lines[1].strip().split()\n",
    "    attr_idx_dict = {attr: i for i, attr in enumerate(attr_list)}\n",
    "    labels_dict = {}\n",
    "    for line in lines[2:]:\n",
    "        line = line.strip().split()\n",
    "        key = line[0]\n",
    "        attr = line[1:]\n",
    "        labels_dict[key] = np.array([int((int(attr[attr_idx_dict[target_attribute]]) + 1) / 2), int((int(attr[attr_idx_dict[protected_attribute]]) + 1) / 2)])\n",
    "\n",
    "    # as per the author's citation, we have transformed the input image\n",
    "    # (resize to , 256×256, 224×224)\n",
    "    pre_process = [(256, 256), (224, 224)]\n",
    "    mean_normalize = (0.485, 0.456, 0.406)\n",
    "    std_normalize = (0.229, 0.224, 0.225)\n",
    "\n",
    "    if augment:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
    "            A.RandomCrop(width=pre_process[1][0], height=pre_process[1][1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
    "        ])\n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(pre_process[0][0], pre_process[0][1]),\n",
    "            A.CenterCrop(width=pre_process[1][0], height=pre_process[1][1]),\n",
    "            A.Normalize(mean=mean_normalize, std=std_normalize)\n",
    "        ])\n",
    "    if num_samples == -1:\n",
    "        num_samples = len(imgs)\n",
    "    else:\n",
    "        print(\"Num. of data ({}) is used for debugging\".format(num_samples))\n",
    "\n",
    "    def load_func(i):\n",
    "        img = Image.open(imgs[i])\n",
    "        img = np.array(img.convert('RGB'))\n",
    "        # transform\n",
    "        transformed_image = transform(image=img)['image'].transpose(2, 0, 1)\n",
    "        return transformed_image, labels_dict[os.path.basename(imgs[i])]\n",
    "\n",
    "    return data_iterator_simple(load_func, num_samples, batch_size, shuffle=shuffle, rng=rng, with_file_cache=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with importing basic modules to switch between CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnabla.ext_utils import get_extension_context\n",
    "context = \"cudnn\" # for cpu set context as 'cpu'\n",
    "device_id = 0\n",
    "ctx = get_extension_context(context, device_id=device_id)\n",
    "nn.set_default_context(ctx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classifier network\n",
    "To train a classifier, we have taken [ResNet-50](https://nnabla.org/pretrained-models/nnp_models/imagenet/Resnet-50/Resnet-50.nnp) pretrained on [ImageNet](https://image-net.org/) as the base architecture. Fully connected layer in ResNet is replaced with two fully connected layers of size 2048. Dropout and ReLU are applied. We train all models with sigmoid cross-entropy loss for 20 epochs with a batch size of 32. We use the [Adam](https://arxiv.org/abs/1412.6980) optimizer with a learning rate of 1e-3.\n",
    "\n",
    "We have trained the Attribute Classifier and saved the model with the best accuracy on the validation set. Now let us get these pre-trained classifier weights and evaluate model fairness. \n",
    "\n",
    "PS:\n",
    "If you want to train the Attribute Classifier from scratch, please refer to our GitHub page and follow the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pre-trained weights\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/prejudice_remover_regularizer_images/best_baseline.h5\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/prejudice_remover_regularizer_images/val_baseline.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "\n",
    "attribute_classifier_model = clf.AttributeClassifier(model_load_path=r'./best_baseline.h5')\n",
    "# split the dataset\n",
    "split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
    "# load dataloader\n",
    "test = data_iterator_celeba(img_path= r'./test',\n",
    "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
    "                            target_attribute ='Attractive', protected_attribute = 'Male',\n",
    "                            batch_size=32)\n",
    "cal_thresh = pickle.load(open(r'./val_baseline.pkl', 'rb'))['cal_thresh']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fairness for Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start our investigation of classifier model fairness by analyzing the predictions made on the test set. In this tutorial, we use the Average Precision (AP) metric to measure classifier accuracy & three metrics to measure model fairness: Calders-Verwer score (CV score), Difference in Equality of Opportunity (DEO) and Bias Amplification (BA). CV Score is the absolute difference between conditional probabilities of the positive class for protected attributes. [DEO](https://arxiv.org/abs/2004.01355) is the absolute difference in False Negative Rate (FNR) for the protected attribute group. [BA](https://arxiv.org/abs/2102.12594) is a metric proposed by Wang and Russakovsky. Intuitively, BA measures how much more often a target attribute is predicted with a protected attribute than the ground truth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets, test_scores = attribute_classifier_model.get_scores(test)\n",
    "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
    "outf = test_scores[test_targets[:, 1] == 0]\n",
    "outm = test_scores[test_targets[:, 1] == 1]\n",
    "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
    "cv_score = utils.get_cvs(outf,outm,cal_thresh)\n",
    "deo = utils.get_diff_in_equal_opportunity(test_targets[:, 1],\n",
    "                                              test_targets[:, 0], test_pred)\n",
    "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
    "                                     test_targets[:, 0], test_pred)\n",
    "\n",
    "# plot the fairness\n",
    "utils.plot_fairness_multi(deo,cv_score,ba,ap,\"Baseline\")\n",
    "print('Test results: ')\n",
    "print('AP : {:.1f}', 100 * ap)\n",
    "print('DEO : {:.1f}', 100 * deo)\n",
    "print('BA : {:.1f}', 100 * ba)\n",
    "print('CV : {:.1f}', 100 * cv_score)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, predictions are definitely not fair when considered in the context of `sex` as a sensitive attribute.\n",
    "\n",
    "Now let's mitigate the bias using `Prejudice Remover Regularizer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prejudice Remover Regularizer\n",
    "\n",
    "Before going to the Prejudice Remover Regularizer method, let's understand what is prejudice and different prejudice methods.\n",
    "\n",
    "**Prejudice:** Prejudice means a statistical dependence between a sensitive variable S, and the target variable, Y, or a non-sensitive variable, X. There are three types of prejudices: `direct prejudice`, `indirect prejudice`, and `latent prejudice`\n",
    "\n",
    "1. Direct prejudice: The prediction model directly depends on S\n",
    "2. Indirect prejudice: Statistical dependence of Y on S, even lack of direct S\n",
    "3. Latent prejudice: Statistical dependence of X on S\n",
    "\n",
    "In this tutorial we discuss how to reduce Indirect prejudice, using the Prejudice Removal Regularization Technique. We next show an index to quantify the degree of indirect prejudice, which is defined as the mutual information between Y and S.\n",
    "$$PI =\\sum_{y,s∈D}\\hat{Pr}[y,s] ln\\frac{\\hat{Pr}[y, s]}{\\hat{Pr}[y]\\hat{Pr}[s]}$$, we refer this index as a `prejudice index`(PI for short)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this PRR technique, there are two types of regularizers. PRR technique involves adding two regularizer terms to cost function: L2 regularizer, $||θ||^2$, to reduce over-fitting and Prejudice remover regularizer, $R(D,θ)$, to enforce fair classification. So, the objective function to minimize is rewritten as :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/Prejudice_Remover_Regularizer_Equation.png')\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where λ and η are positive regularization parameters.\n",
    "\n",
    "in the above equation prejudice remover regularizer:\n",
    "* Directly tries to reduce the prejudice index(PI).\n",
    "* Smaller value more strongly constraints independence b/w Y and S\n",
    "\n",
    "in short :\n",
    "\n",
    "PRLR : Loss function(log-likelihood) + Prejudice Remover Regularizer(mutual information) + l2 Regularizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained the PRR model and saved the model with the best accuracy on the validation set. If you want to train the PRR model from the scratch please refer to our GitHub page and follow the steps.\n",
    "\n",
    "Now let us get the pre-trained weights for the PRR and load the model. The supplied λ and η values, that tune fairness versus accuracy, are set to λ = 1e-05 and η = 2 (If η is 0, the network behaves as a simple base class classifier network). We heuristically found that these settings result in a balanced increase of the fairness value during training. You may train with different regularization parameter values and check the impact of different λ and η values on model performance and fairness.\n",
    "\n",
    "Let's check the model fairness after PRR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/prejudice_remover_regularizer_images/best_prr.h5\n",
    "!wget https://nnabla.org/pretrained-models/nnabla-examples/responsible_ai/prejudice_remover_regularizer_images/val_prr.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()\n",
    "\n",
    "attribute_classifier_model = clf.AttributeClassifier(model_load_path=r'./best_prr.h5')\n",
    "# split the dataset\n",
    "# split_celeba_dataset(r'./data/celeba/images', r'./data/celeba/list_attr_celeba.txt', r'./test',split=\"test\")\n",
    "# load dataloader\n",
    "test = data_iterator_celeba(img_path= r'./test',\n",
    "                            attr_path= r'./data/celeba/list_attr_celeba.txt',\n",
    "                            target_attribute ='Attractive', protected_attribute = 'Male',\n",
    "                            batch_size=32)\n",
    "cal_thresh = pickle.load(open(r'./val_prr.pkl', 'rb'))['cal_thresh']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fairness: with PRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets, test_scores = attribute_classifier_model.get_scores(test)\n",
    "test_pred = np.where(test_scores > cal_thresh, 1, 0)\n",
    "outf = test_scores[test_targets[:, 1] == 0]\n",
    "outm = test_scores[test_targets[:, 1] == 1]\n",
    "ap = utils.get_average_precision(test_targets[:, 0], test_scores)\n",
    "\n",
    "cv_score = utils.get_cvs(outf,outm,cal_thresh)\n",
    "\n",
    "deo = utils.get_diff_in_equal_opportunity(test_targets[:, 1],\n",
    "                                                     test_targets[:, 0], test_pred)\n",
    "ba = utils.get_bias_amplification(test_targets[:, 1],\n",
    "                                     test_targets[:, 0], test_pred)\n",
    "\n",
    "utils.plot_fairness_multi(deo,cv_score,ba,ap,\"PRR\")\n",
    "print('Test results: ')\n",
    "print('AP : {:.1f}', 100 * ap)\n",
    "print('DEO : {:.1f}', 100 * deo)\n",
    "print('BA : {:.1f}', 100 * ba)\n",
    "print('CV : {:.1f}', 100 * cv_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots above show how model fairness improved after induction of PRR into training. DEO & CV score have improved compared to the baseline model. After PRR training, classification accuracy has dropped. But, it can be controlled. Ideally, user must take a call on acceptable amount of trade off between accuracy and fairness. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Summary\n",
    " \n",
    "In this tutorial, we have demonstrated how to reduce indirect prejudice using `Prejudice Remover Regularizer` procedure in a visual recognition task.\n",
    "Also, note that it is not possible to optimize a model for all the fairness metrics in real-time: to read more about this, explore the [Impossibility Theorem of Machine Fairness](https://arxiv.org/abs/2007.06024).\n",
    "\n",
    "Also, making fair predictions comes at a cost: sometimes it will reduce the performance [AP] of our model (hopefully, only little). However, in many cases, this would be a small price to pay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"Fairness-aware classifier with prejudice remover regularizer\". Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh & Jun Sakuma. Joint European Conference on Machine Learning and Knowledge Discovery in Databases ECML PKDD 2012: Machine Learning and Knowledge Discovery in Databases pp 35–50.\n",
    "2. \"Equality of opportunity in supervised learning\". Hardt, Moritz, Eric Price, and Nati Srebro.Advances in neural information processing systems 29 (2016)\n",
    "3. \"Directional bias amplification\". Wang, Angelina, and Olga Russakovsky. International Conference on Machine Learning. PMLR, 2021.\n",
    "4. \"The Impossibility Theorem of Machine Fairness--A Causal Perspective\".Saravanakumar, Kailash Karthik. arXiv preprint arXiv:2007.06024 (2020).\n",
    "5. \"Adam: A method for stochastic optimization\". Kingma, Diederik P., and Jimmy Ba. arXiv preprint arXiv:1412.6980 (2014).\n",
    "6. \"Large-scale celebfaces attributes (celeba) dataset\". Liu, Ziwei, Ping Luo, Xiaogang Wang, and Xiaoou Tang.  Retrieved August 15, no. 2018 (2018): 11.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
